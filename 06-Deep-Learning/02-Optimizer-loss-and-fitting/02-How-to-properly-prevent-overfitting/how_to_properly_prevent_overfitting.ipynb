{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to properly prevent overfitting\n",
    "\n",
    "**Objective**\n",
    "- Give a validation set to the model\n",
    "- Use the stopping criterion to prevent the Neural network from overfitting\n",
    "- Regularize your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "First, let's generate some data thanks to the [`make_blob`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) function that we used yesterday.\n",
    "\n",
    "❓ **Question** ❓ Generate 2000 samples, with 10 features each. There should be 8 classes of blobs (`centers` argument), wich `cluster_std` equal to 7. Plot some dimensions to check your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:13:35.826987Z",
     "start_time": "2021-04-20T09:13:35.696628Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, n_features=10, centers=8, cluster_std=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 10), (2000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 3], X[:, 8], c=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Use the `to_categorical` function from `tensorflow` to convert `y` to `y_cat` which is the categorical representation of `y` with one-hot encoding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat = to_categorical(y, num_classes=8)\n",
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part I : Proper cross-validation\n",
    "\n",
    "In a previous challenge, we split the dataset into a train and a test set at the beginning of the notebook. And then, we started to build different models which were trained on the train set but evaluated on the test set.\n",
    "\n",
    "So, at the end of the day, we used the test set as many times as we evaluated our models and different hyperparameters. We therefore _used_ the test set to select our best model, which is a sort of overfitting.\n",
    "\n",
    "A first good practice is to avoid using `random_state` or any deterministic separation between your train and test set. In that case, your test set will change everytime you re-run your notebook. But this is far from being sufficient.\n",
    "\n",
    "To properly compare models, you have to run a proper cross-validation, a 10-fold split for instance. Let's see how to do it properly.\n",
    "\n",
    "❓ **Question** ❓ First, write a function that outputs a neural network with 3 layers\n",
    "- a layer with 25 neurons, the `relu` activation function and the appropriate `input_dim`\n",
    "- a layer with 10 neurons and the `relu` activation function.\n",
    "- a last layer which is suited to the problem at hand (multiclass classification)\n",
    "\n",
    "The function should include its compilation, with the `categorical_crossentropy` loss, the `adam` optimizer and the `accuracy` metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:19:05.297810Z",
     "start_time": "2021-04-19T15:19:05.295243Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:19:05.305507Z",
     "start_time": "2021-04-19T15:19:05.300766Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(25, activation='relu', input_dim=10))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 25)                275       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 88        \n",
      "=================================================================\n",
      "Total params: 623\n",
      "Trainable params: 623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will do a proper cross validation.\n",
    "\n",
    "❓ **Question** ❓ Write a loop thanks to the [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function of Scikit-Learn (select 10 splits) to fit your model on the train data, and evaluate it on the test data. Store the result of the evaluation in the `results` variable.\n",
    "\n",
    "Do not forget to standardize your train data before fitting the neural network.\n",
    "Also, 150 epochs shoul be sufficient in a first approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:19:05.342885Z",
     "start_time": "2021-04-19T15:19:05.308384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 200  201  202 ... 1997 1998 1999] TEST: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 1s 2ms/step - loss: 2.0608 - accuracy: 0.1989\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.8702 - accuracy: 0.3643\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.6210 - accuracy: 0.4963\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3983 - accuracy: 0.5548\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1845 - accuracy: 0.6143\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.6555\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.6850\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8414 - accuracy: 0.7409\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7787 - accuracy: 0.7593\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.7648\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.7057 - accuracy: 0.7715\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6734 - accuracy: 0.7808\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6820 - accuracy: 0.7672\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.7668\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.7716\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7922\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7957\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.7797\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7826\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.7747\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7763\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.7819\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7843\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7837\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7748\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7756\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7898\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7864\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7994\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7702\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7935\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7919\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7887\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7899\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7792\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.8049\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7842\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7887\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.8015\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7835\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7987\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7915\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7879\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7961\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7826\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8093\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.8039\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.8017\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.8088\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7958\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.8028\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7902\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7917\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7995\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7768\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7783\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7916\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7977\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7935\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.8069\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8125\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5679 - accuracy: 0.7963\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7960\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.8113\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7871\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.8091\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.8096\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7968\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7900\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7924\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8024\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.8099\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8156\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8043\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7918\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8020\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7962\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7976\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8130\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.8034\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.8041\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8105\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.8140\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.8125\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8127\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7954\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7998\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7903\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8117\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.8036\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8195\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7900\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.8011\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8070\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.8109\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8362\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7913\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.8049\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8009\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8098\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8303\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.8000\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.8084\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8097\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8194\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8230\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.8156\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.8118\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8275\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.8101\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8119\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8046\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8144\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8074\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8149\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8161\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8253\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8073\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.8300\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7988\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8079\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8265\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.8096\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8065\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8074\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8186\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8301\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5340 - accuracy: 0.8030\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8383\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8184\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8201\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8423\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.8143\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8144\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8202\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8151\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8251\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8291\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4889 - accuracy: 0.8255\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8277\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.8150\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8138\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8133\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8264\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8164\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.8182\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.8161\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.5199 - accuracy: 0.8240\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4889 - accuracy: 0.8261\n",
      "7/7 [==============================] - 1s 7ms/step - loss: 0.6207 - accuracy: 0.7600\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\n",
      " 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271\n",
      " 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307\n",
      " 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325\n",
      " 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343\n",
      " 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361\n",
      " 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379\n",
      " 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397\n",
      " 398 399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 2.1447 - accuracy: 0.0856\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.9492 - accuracy: 0.2372\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.7721 - accuracy: 0.4036\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5344 - accuracy: 0.5072\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3126 - accuracy: 0.5787\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1216 - accuracy: 0.6466\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.9749 - accuracy: 0.6838\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.7174\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8081 - accuracy: 0.7247\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.7507\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.7716\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.7684\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.7750\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7717\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7829\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7722\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7912\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.7848\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.7903\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.7865\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.7838: 0s - loss: 0.6836 - ac\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6003 - accuracy: 0.7862\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5548 - accuracy: 0.8037\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7961\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5389 - accuracy: 0.8011\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5786 - accuracy: 0.7934\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.8125\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8010\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7999\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5734 - accuracy: 0.7970\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5085 - accuracy: 0.8236: 1s - loss: 0.4238 - accura\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7897\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7996\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7970\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5954 - accuracy: 0.7869\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.8203\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5617 - accuracy: 0.7986\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5698 - accuracy: 0.7897\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5500 - accuracy: 0.8042\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.8099\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5659 - accuracy: 0.7907\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.8060\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7917\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.5314 - accuracy: 0.8023 4s - loss: 0.4710 - accura\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.8079\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8138\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8153\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8074\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7941\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8105\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8278\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7913\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8102\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8187\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.8016\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8280\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7785\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8108\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.8081\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8180\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8252\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8019\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8186\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7959\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8114\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8262\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8300\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8141\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8171\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8044\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.8351\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8136\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8179\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8067\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8109\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8127\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.8011\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8183\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8125\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8268\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8119\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8148\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8140\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8315\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.8301\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.8216\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8178\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8402\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8036\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8157\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8190\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8282\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8276\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8358\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8116\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8193\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.8259\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8198\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8236\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8210\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8332\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8319\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8275\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8279\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8345\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8300\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8248\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8268\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8203\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.8200\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8329\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8182\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8264\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8155\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.8239\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8187\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8176\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8332\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8244\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8204\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8228\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8402\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8277\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8369\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8384\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.8269\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8320\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8348\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8257\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8141\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8187\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8377\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8319\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8182\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8318\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8294\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8330\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8082\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8394\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8349\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8151\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8322\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8316\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8388\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8289\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8268\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8378\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8283\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8323\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8482\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8374 - accuracy: 0.7250\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417\n",
      " 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435\n",
      " 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453\n",
      " 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471\n",
      " 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489\n",
      " 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507\n",
      " 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525\n",
      " 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543\n",
      " 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561\n",
      " 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579\n",
      " 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597\n",
      " 598 599]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 2.1025 - accuracy: 0.1188\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.9046 - accuracy: 0.2993\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.6473 - accuracy: 0.4924\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3894 - accuracy: 0.5610\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1713 - accuracy: 0.6277\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9971 - accuracy: 0.6547\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.8669 - accuracy: 0.7153\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.8306 - accuracy: 0.7348\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.7544\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.7529\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7723\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.7861\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.7635\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.7690\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7864\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.7815\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7870\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.8026\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7786\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.8010\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.7808\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7818\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7940\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7880\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7983\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7944\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.8060\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7818\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7940\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7784\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7842\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8117\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.8057\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7962\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7906\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7916\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7870\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7992\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7953: 1s - loss: 0.4397 - accuracy: \n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7903\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7886\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7864\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.8066\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7870\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7866\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8027\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8041\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7955\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7970\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.8069\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.8079\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.8004\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7939\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.8022\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7996\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.8082\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7923\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8107\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8025\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7968\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7974\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7975\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7933\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8078\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7866\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7967\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8140\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7986\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.8032\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7791\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8021\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8059\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7987: 0s - loss: 0.5355 - accuracy: 0.\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8185\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7965\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8163\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8054\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8029\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7988\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8020\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8261\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8057\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8257\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8184\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.8135\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8177\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.8035\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8240\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.8190\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8058\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8150\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8018\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8079\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7991\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8140\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8151: 0s - loss: 0.4839 - accuracy: 0.81\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5046 - accuracy: 0.8049: 1s - loss: 0.5176 - accu\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.8153\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8087\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8266\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7975\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8173\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8162\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8137\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8248\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8161\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8176\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8199\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8153\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8059\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8249\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8198\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8181\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.8091\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7979\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.8270\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.8021\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8026\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8085\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.8318\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8165\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8260\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8122\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8277\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4677 - accuracy: 0.8261\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.8181\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8068\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8148\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8104\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8124\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.8161\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.8143\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8217\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8251\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.8238\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.8191\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8251\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8318\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8174\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.8250\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8208\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.8207\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8155\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8292\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.8285\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.8265\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8105\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8196\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.8182\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7487 - accuracy: 0.7650\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617\n",
      " 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635\n",
      " 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653\n",
      " 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671\n",
      " 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689\n",
      " 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707\n",
      " 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725\n",
      " 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743\n",
      " 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761\n",
      " 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779\n",
      " 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797\n",
      " 798 799]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 1s 2ms/step - loss: 2.0734 - accuracy: 0.1233\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7761 - accuracy: 0.3300\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5803 - accuracy: 0.4674\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3723 - accuracy: 0.5974: 0s - loss: 1.4170 - accuracy: 0.\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.1727 - accuracy: 0.6465\n",
      "Epoch 6/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.6816\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8918 - accuracy: 0.7161\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.7074\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.7492\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.7643\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.7766\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.7854\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7756\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7673\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7669\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7864\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.7776\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.7814\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7923: 0s - loss: 0.5727 - accuracy: \n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7837\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7743\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7865\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7644\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7831\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.8059\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7926\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7902\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7856\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7853\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.7944\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7935\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.8032\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.8088\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7941\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7994\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7914\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.7823\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.8102\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.8001\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.8089\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7823\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7976\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7916\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7988\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.8042\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7982\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7796\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7953\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7937\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7984\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7983\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7969\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7982\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7992\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8103\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.8113\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8161\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8117\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.8069\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.8071\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8110\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7921\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8033\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7823\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.8117\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7951\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.8056\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7964\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8098\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8236\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8182\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8169\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8197\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8236\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.8049\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8031\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8193\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8144\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8368\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7991\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8144\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8194\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8310\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8062\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8202\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8110\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8193\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.8123\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8076\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8163\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8038\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.8213\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.8163\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4902 - accuracy: 0.8188\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.8329\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.4856 - accuracy: 0.8295 0s - loss: 0.4768 - accura\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4639 - accuracy: 0.8347 0s - loss: 0.3763 - \n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.8276\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.8170\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8215\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8105\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.8076\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8245\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8228\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.5153 - accuracy: 0.8145\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4927 - accuracy: 0.8219\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4791 - accuracy: 0.8215\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8254\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8104\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8178\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.8278\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8035\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8291\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8098\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8290\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8177\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8186\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8084\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8237\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8363\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8299\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8210\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8190\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8341\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8136\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8236\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8384\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8154\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8198\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8283\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8194\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8198\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.8012\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8383\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.8322\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8326\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8266\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.8194\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.8231\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.8199\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5013 - accuracy: 0.8065\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.4547 - accuracy: 0.8297 0s - loss: 0.4166 \n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8211\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8333\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8168\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8264\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8252\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8360\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8292\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8219\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.7400\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817\n",
      " 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835\n",
      " 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853\n",
      " 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871\n",
      " 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889\n",
      " 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907\n",
      " 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925\n",
      " 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943\n",
      " 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961\n",
      " 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979\n",
      " 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997\n",
      " 998 999]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 2.1416 - accuracy: 0.0751\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9403 - accuracy: 0.2908\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7413 - accuracy: 0.4810\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.4618 - accuracy: 0.6008\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1862 - accuracy: 0.6844\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.7163\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8659 - accuracy: 0.7503\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.7528\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.7786\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7694\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.7675\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.7837\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6306 - accuracy: 0.7884\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7907\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7912\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7852\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7979\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7923\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7961\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8048\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8183\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.8060: 0s - loss: 0.5464 - accuracy: 0.\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8158\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5669 - accuracy: 0.7980\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8130\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5499 - accuracy: 0.8234\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.5165 - accuracy: 0.8180\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5397 - accuracy: 0.8059\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8139\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7958\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7911\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5557 - accuracy: 0.8004\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.5557 - accuracy: 0.8063\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.8007\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5221 - accuracy: 0.8117\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.8092\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.8082\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8113\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5231 - accuracy: 0.8252\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.8029\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8136\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.8078\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8169\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.8029\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.8194\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.8150\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.8170\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8189\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.8010\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8240\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.8136\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8105\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.8046\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.8026\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8133\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8254\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8158\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8199\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.8091\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8272\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8446\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8064\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8238\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8151\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8194\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8094\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8320\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8099\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8238\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.8213\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.8105\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.8233\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8254\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8211\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8108\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.8201\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8239\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8206\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8209\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8306\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8283\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8230\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8180\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8182\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8239\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8301\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8318\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.8156\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8308\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8249\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8200\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8314\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8335\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8186\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.8070\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8276\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8163\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8259\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8318\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8310\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8223\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.8295\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8227\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8489\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8220\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8317\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8257\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8338\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8248\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8289\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.8337\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8356\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8353\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8363\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8313\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8272\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8243\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8205\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8341\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8367\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8237\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8229\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.8152\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8196\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8417\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8375\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8310\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8298\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.8356\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8308\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8250\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8283\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8279\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8302\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.8289\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.8351\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.8334\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8360\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8387\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.8265\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8302\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8340\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8360\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8330\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.8194\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.8290\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8349\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8297\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8474\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8341\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8532 - accuracy: 0.7450\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013\n",
      " 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027\n",
      " 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055\n",
      " 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069\n",
      " 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083\n",
      " 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097\n",
      " 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111\n",
      " 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125\n",
      " 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139\n",
      " 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153\n",
      " 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167\n",
      " 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181\n",
      " 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195\n",
      " 1196 1197 1198 1199]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 2.0379 - accuracy: 0.1343\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.7881 - accuracy: 0.3559\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.6013 - accuracy: 0.5376\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.4171 - accuracy: 0.6323\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1708 - accuracy: 0.6907\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9964 - accuracy: 0.7406\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.8537 - accuracy: 0.7405\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7358 - accuracy: 0.7655\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7637\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.7803\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7622\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.7812\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.7840\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.7986\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.7849\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.7813\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.7818\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.7903\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7700\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.7834\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.8128\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.7887\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.8013\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.7974\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.8084\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.8080\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.8000\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.8047\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.7790\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.8037\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.8145\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.8136\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7913\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7988\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7902\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7979\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.8055\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7917\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.8151\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7938\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7836\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8202\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7959\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.8058\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.8170\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8213\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.8006\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7957\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.8068\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.8160\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7924\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.8105\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.8111\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8160\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.8007\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.8026\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.8138\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.8063\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.8250\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8069\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8223\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8085\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8114\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8140\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.8206\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.8122\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.8073\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8250\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.8071\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8245\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.8032\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8163\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8241\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.8098\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8170\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8178\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8291\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.8110\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8273\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.8013\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8139\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8085\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8105\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.8008\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.8167\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.8115\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8253\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8202\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8262\n",
      "Epoch 91/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.8137\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8183\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8224\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8193\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.8283\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.8072\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.8170\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8297\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.8205\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.8301\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8337\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8220\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8142\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8136\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8259\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8280\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8318\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8175\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8321\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.8299\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.8385\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8285\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8224\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8151\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.8226\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8237\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8315\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8256\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8248\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8261\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.8287\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8293\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8110\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.8170\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8311\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8263\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.8195\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8256\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8338\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8275\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8207\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8362\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8256\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8397\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.8388\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8204\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8362\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8428\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8146\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8317\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8205\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8238\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8330\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8282\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8419\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8143\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.8332\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8280\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8260\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.7700\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213\n",
      " 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227\n",
      " 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241\n",
      " 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255\n",
      " 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269\n",
      " 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283\n",
      " 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297\n",
      " 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311\n",
      " 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325\n",
      " 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339\n",
      " 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353\n",
      " 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367\n",
      " 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381\n",
      " 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395\n",
      " 1396 1397 1398 1399]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 2.1053 - accuracy: 0.1362\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.8549 - accuracy: 0.3714\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5873 - accuracy: 0.5362\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.2861 - accuracy: 0.6536\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.6949\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.7332\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7837 - accuracy: 0.7664\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.7721\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.7892\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.7687\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.7744\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.7810\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.7844\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.7738\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.7803\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.7729\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7888\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7792\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.7872\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.7800\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7845\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7849\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.7669\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.7705\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.7844\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7944\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.7817\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7895\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7998\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.7729\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7957\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7759\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.7775\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.8037\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7976\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7948\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7873\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7928\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7882\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7947\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.7766\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7978\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.8024\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7930\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7892\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7919\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.8086\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8004\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.7969\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7943\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7955\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7959\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7905\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7873\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8013\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.8131\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7790\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.8017\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7923\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7877\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8187\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7958\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7890\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.8115\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8129\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.8010\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7994\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7938\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.8104\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.8035\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7977\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7898\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.8112\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7958\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7958\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.8077\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7964\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7973\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.8048\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8144\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.8146\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7916\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.8029\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7939\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8178\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8100\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7956\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8197\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7936\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8018\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.8097\n",
      "Epoch 93/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.8035\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.8096\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8214\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7987\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8075\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7998\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8276\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.8049\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8175\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8353\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7977\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.8185\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.8198\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8185\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.8159\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8041\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8341\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8061\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8267\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.8125\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.8143\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8270\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8140\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8040\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.8101\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8123\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8173\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.8301\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7955\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8143\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.8059\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8321\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8248\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8326\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8061\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8176\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8283\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8093\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8380\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8221\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8193\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.8193\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8011\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8252\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8092\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7978\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.8168\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8131\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8283\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8055\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7980\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8132\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8237\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8104\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8221\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.8209\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8257\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8173\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.7850\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413\n",
      " 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427\n",
      " 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441\n",
      " 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455\n",
      " 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469\n",
      " 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483\n",
      " 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497\n",
      " 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511\n",
      " 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525\n",
      " 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539\n",
      " 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553\n",
      " 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567\n",
      " 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581\n",
      " 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595\n",
      " 1596 1597 1598 1599]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 2.0848 - accuracy: 0.1473\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.8691 - accuracy: 0.3432\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.6435 - accuracy: 0.4466\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.4377 - accuracy: 0.5266\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.2839 - accuracy: 0.5523\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.1489 - accuracy: 0.5961\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.6409\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9268 - accuracy: 0.6818\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6997\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.7279\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.7568 - accuracy: 0.7431\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.7658\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.7598\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.7374\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.7793\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.7729\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.7872\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.7778\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.7764\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.7895\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.8019\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.7930\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.7813\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.8004\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.8071\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7906\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.7967\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.8096\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.8071\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.8090\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7992\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8042\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.8087\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7974\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.8097\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7870\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7929\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7989\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7925\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.8001\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.8070\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.8021\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7934\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.8145\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8188\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8085\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.8163\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8117\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8094\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.8139\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.8146\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8130\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8151\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8226\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.8193\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.8145\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.8185\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7961\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.8157\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.8124\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.8034\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.8093\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.8130\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.8243\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7983\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.8121\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.8167\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.8165\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.8149\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8211\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.8061\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8169\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8239\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8162\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.8141\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.8311\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.8126\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.8102\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.8260\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8094\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.8041\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.8043\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8262\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.8145\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8224\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.8298\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8184\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.8213\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8075\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8268\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8210\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8343\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8096\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8336\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8144\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8289\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8362\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8125\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.8241\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8328\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8393\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8340\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8281\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8155\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8341\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8232\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.8249\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8288\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.8311\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.8169\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8325\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.8240\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8161\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8286\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8166\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8297\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.8263\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8310\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8213\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.8359\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8297\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.8378\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8298\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8351\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8486\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.8235\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8228\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8168\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8291\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8306\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.8280\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8211\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8229\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8372\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8482\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.8407\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.8145\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8325\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8140\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8226\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.8353\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.8281\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8283\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.8201\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8460\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8285\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8366\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8259\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8321\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8271\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7549 - accuracy: 0.7600\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613\n",
      " 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627\n",
      " 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641\n",
      " 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655\n",
      " 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669\n",
      " 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683\n",
      " 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697\n",
      " 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711\n",
      " 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725\n",
      " 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739\n",
      " 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753\n",
      " 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767\n",
      " 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781\n",
      " 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795\n",
      " 1796 1797 1798 1799]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.0579 - accuracy: 0.2306\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.8561 - accuracy: 0.3341\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.6255 - accuracy: 0.4581\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3733 - accuracy: 0.5649\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1716 - accuracy: 0.6485\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.0180 - accuracy: 0.6823\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8660 - accuracy: 0.7478\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8004 - accuracy: 0.7551\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.7657\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7447 - accuracy: 0.7483\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.7548\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.7571\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.7824\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.7790\n",
      "Epoch 15/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.7778\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.7936\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.7912\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7738\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.7796\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.7820\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7926\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.8016\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.7791\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7963\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.7817\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.8096\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7886\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.7998\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.8017\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.8009\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7880\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.8036\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7904\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.8037\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.7830\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.7868\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7979\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8063\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.8037\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.8062\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.7951\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.8043\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.8164\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7976\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.8110\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7927\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.8080\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.8030\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.8161\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.8003\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7998\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.8052\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.8001\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8253\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7858\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.8081\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.8181\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8212\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.8188\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.8121\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8118\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8186\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8101\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.8243\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7997\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7960\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.8095\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.8181\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.8025\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.8123\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.8125\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8172\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7958\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8184\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.8025\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.8106\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.8105\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8169\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8204\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8218\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8347\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.8096\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.8061\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7951\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8295\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8361\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.8021\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.8123\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8300\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.8289\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.8123\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8245\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8208\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8192\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8131\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.8118\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8318\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8298\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8180\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.8248\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8297\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8255\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8283\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.8180\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8268\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8332\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8197\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8201\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.8012\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8305\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8185\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8272\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.8106\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8266\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.8038\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8328\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8266\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8377\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8374\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8249\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8249\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.8365\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.8156\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.8229\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8348\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8333\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.8234\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.8172\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8352\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8325\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8257\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8263\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8244\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8324\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8290\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8115\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.8085\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8227\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8168\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8280\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8337\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8333\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8228\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8415\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8276\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8240\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8180\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8203\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8299\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7700\n",
      "TRAIN: [   0    1    2 ... 1797 1798 1799] TEST: [1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813\n",
      " 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827\n",
      " 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841\n",
      " 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855\n",
      " 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869\n",
      " 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883\n",
      " 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897\n",
      " 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911\n",
      " 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925\n",
      " 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939\n",
      " 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953\n",
      " 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967\n",
      " 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981\n",
      " 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n",
      " 1996 1997 1998 1999]\n",
      "Epoch 1/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 2.0528 - accuracy: 0.1580\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 1.7820 - accuracy: 0.3628\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5178 - accuracy: 0.5104\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 1.2556 - accuracy: 0.6412\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.0165 - accuracy: 0.7256\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.7441\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7921 - accuracy: 0.7595\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.7650\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.7675\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.7827\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7781\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6207 - accuracy: 0.8028\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7944\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.7852\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.7822\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7882\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7854\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.7887\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.7846\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.7855\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.7942\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.7900\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7997\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.8076\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.8036\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.7985\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.7804\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.8052\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.8003\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.8018\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.8040\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.7731\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5467 - accuracy: 0.8082\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7809\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7942\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.8057\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.8195\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.8081\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7981\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7912\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.8017\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7990\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.7749\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.8136\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.8136\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7878\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.8038\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.8121\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.8147\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.8126\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.8122\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.8094\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7989\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.8105\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.8040\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8147\n",
      "Epoch 57/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.8086\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.8033\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.8199\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8104\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8129\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7936\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8170\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.8030\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.8206\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8064\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7920\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.8039\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7990\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8063\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.8069\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8130\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8129\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8168\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8266\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8062\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.8070\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.8092\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8049\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8207\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8154\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8149\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.8014\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8033\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8111\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.8017\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8093\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.8025\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8184\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.8091\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.8243\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.8069\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8197\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.8000\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.8149\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8137\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8092\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.8004\n",
      "Epoch 99/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8121\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8215\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8104\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8178\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8230\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.8071\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8218\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.8142\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8143\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.8134\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.8284\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8192\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.8074\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8252\n",
      "Epoch 113/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8231\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.8026\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8188\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8130\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8201\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8205\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8184\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.8212\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.8129\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.8048\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.8135\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8300\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.8310\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.8049\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8109\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8207\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8179\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.8188\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8375\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.8123\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8158\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.8141\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.8350\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.8260\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8271\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8099\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.8131\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8119\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8226\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.8256\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8134\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.8077\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8153\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8177\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8222\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8172\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.8227\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8362\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7496 - accuracy: 0.7450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.6207223534584045, 0.7599999904632568],\n",
       " [0.8374118804931641, 0.7250000238418579],\n",
       " [0.7486841082572937, 0.7649999856948853],\n",
       " [0.6954187154769897, 0.7400000095367432],\n",
       " [0.8531550765037537, 0.7450000047683716],\n",
       " [0.6921131014823914, 0.7699999809265137],\n",
       " [0.6108787655830383, 0.7850000262260437],\n",
       " [0.7548871636390686, 0.7599999904632568],\n",
       " [0.6080772280693054, 0.7699999809265137],\n",
       " [0.7495566606521606, 0.7450000047683716]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    # Split the data into train and test\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_cat[train_index], y_cat[test_index]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = initialize_model() \n",
    "    \n",
    "    # Fit the model on the train data\n",
    "    model.fit(X_train, \n",
    "              y_train,\n",
    "              epochs=150)\n",
    "    \n",
    "    # Evaluate the model on the test data and append the result in the `results` variable\n",
    "    results.append(model.evaluate(X_test, y_test))\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6207223534584045, 0.7599999904632568],\n",
       " [0.8374118804931641, 0.7250000238418579],\n",
       " [0.7486841082572937, 0.7649999856948853],\n",
       " [0.6954187154769897, 0.7400000095367432],\n",
       " [0.8531550765037537, 0.7450000047683716],\n",
       " [0.6921131014823914, 0.7699999809265137],\n",
       " [0.6108787655830383, 0.7850000262260437],\n",
       " [0.7548871636390686, 0.7599999904632568],\n",
       " [0.6080772280693054, 0.7699999809265137],\n",
       " [0.7495566606521606, 0.7450000047683716]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Print the mean accuracy, and its standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.781205952167511, 0.056205928325653076)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = np.array(results)[1].mean(), np.array(results)[1].std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **Remark** ❗ You probably encountered one of the drawback of using a proper cross-validation for a neural network: **it takes a lot of time**. Therefore, for the rest of deep-learning module, we will do **only one split**. But remember that this is not entirely correct and, for real-life applications and problems, you are encouraged to use a proper cross-validation technique.\n",
    "\n",
    "❗ **Remark** ❗ In general, what practitioners do, is that they split only once, as you did. And once they get to the end of their optimization, they launch a real cross-validation at 6pm, go home and get the final results on the next day.\n",
    "\n",
    "❓ **Question** ❓ For the rest of the exercise (and of the deep-learning module), split the dataset into train and test with a 70/30% training to test data ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:20:28.379004Z",
     "start_time": "2021-04-19T15:20:28.375641Z"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II : Stop the learning before overfitting\n",
    "\n",
    "Let's first show that if we train the model for too long, it will overfit the training data and will not be good on the test data.\n",
    "\n",
    "❓ **Question** ❓ To do that, train the same neural network (do not forget to re-initialize it) with `validation_data=(X_test, y_test)` and 500 epochs. Store the history in the `history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:20:28.390338Z",
     "start_time": "2021-04-19T15:20:28.388118Z"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate the model on the test set and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:10.154647Z",
     "start_time": "2021-04-19T15:21:10.152114Z"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Plot the history of the model with the following function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:29:59.503878Z",
     "start_time": "2021-04-19T15:29:59.498538Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(13,5))\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylim((0,3))\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "    \n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "    ax[1].set_ylim((0,1))\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:10.221065Z",
     "start_time": "2021-04-19T15:21:10.219085Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the number of epochs we choose has a great influence on the final results: \n",
    "- If not enough epochs, then the algorithm is not optimal as it has not converged yet. \n",
    "- On the other hand, if too many epochs, we overfit the training data and the algorithm does not generalize well on test data.\n",
    "\n",
    "What we want is basically to stop the algorithm when the test loss is minimal (or the test accuracy is maximal).\n",
    "\n",
    "Let's introduce the early stopping criterion which is a way to stop the epochs of the algorithm at a interesting epoch. It basically use part of the data to see if the test loss stops from improving. You cannot use the test data to check that, otherwise, it is some sort of data leakage. On the contrary, it uses a subset of the initial training data, called the **validation set**\n",
    "\n",
    "It basically looks like the following : \n",
    "\n",
    "<img src=\"validation_set.png\" alt=\"Validation set\" style=\"height:350px;\"/>\n",
    "\n",
    "To split this data, we use, in the `fit` function, the `validation_split` keyword which sets the percentage of data from the initial training set used in the validation set. On top of that, we use the `callbacks` keyword to call the early stopping criterion at the end of each epoch. You can check additional information in the [documentation](https://www.tensorflow.org/guide/keras/train_and_evaluate)\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Launch the following code, plot the history and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:12.643470Z",
     "start_time": "2021-04-19T15:21:10.548410Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping()\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "# Fit the model on the train data\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.3,\n",
    "                    epochs=500,\n",
    "                    batch_size=16, \n",
    "                    verbose=0, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:12.643470Z",
     "start_time": "2021-04-19T15:21:10.548410Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **Remark** ❗ The problem, with this type of approach, is that as soon as the loss of the validation set increases, the model stops. However, as neural network convergence is stochastic, it happens that the loss increases before decreasing again. For that reason, the Early Stopping criterion has the `patience` keyword that defines how many epochs without loss decrease you allow.\n",
    "\n",
    "❓ **Question** ❓ Use the early stopping criterion with a patience of 30 epochs, plot the results and print the accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:12.648386Z",
     "start_time": "2021-04-19T15:21:12.645794Z"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **Remark** ❗ The model continues to converge even though it has some loss increase and descrease. The number of patience epochs to select is highly related to the task at hand and there does not exist any general rule. \n",
    "\n",
    "❗ **Remark** ❗ In case you select a high patience, you might face the problem that the loss on the test set decrease a lot from the best position. To that end, the early stopping criterion allows you to stop the convergence _and_ restore the weights of the neural network when it had the best score on the validation set, thanks to the `restore_best_weights` that is set to `False` by default.\n",
    "\n",
    "❓ **Question** ❓ Run the model with a early stopping criterion that enables to restore the best weights of the parameters, plot the loss and accuracy and print the accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:17.270730Z",
     "start_time": "2021-04-19T15:21:17.268655Z"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **Remark 1** ❗ You can look at the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to play with other parameters\n",
    "\n",
    "❗ **Remark 2** ❗ No need to take a look at the epochs as long as it hit the stopping criterion. So, in the future, you should have a large number of epochs and the early stopping criterion has to stop the epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III : Batch-size & Epochs\n",
    "\n",
    "❓ **Question** ❓ Let's run the previous model with different batch sizes (with the early stopping criterion) and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:33:34.784883Z",
     "start_time": "2021-04-19T15:33:09.545758Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL (it can take some time)\n",
    "\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "for batch_size in [1, 4, 32]:\n",
    "    \n",
    "    model = initialize_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=0.3,\n",
    "                        epochs=500,\n",
    "                        batch_size=batch_size, \n",
    "                        verbose=0, \n",
    "                        callbacks=[es])\n",
    "\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    plot_loss_accuracy(history, title=f'------ BATCH SIZE {batch_size} ------\\n The accuracy on the test set is of {results[1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Look at the oscillations of the accuracy and loss with respect to the batch size number. Is this coherent with what we saw with the Tensorflow Playground? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:21:56.885224Z",
     "start_time": "2021-04-19T15:21:56.882115Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ How many optimizations of the weight are they within one epoch, with respect to the number of data and the batch size? Therefore, is one epoch longer with a large or a small bacth size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm455OX6ksyl"
   },
   "source": [
    "# Part IV: Regularization\n",
    "\n",
    "In this part of the notebook, we will see how to use regularizers in a neural network. Regularizers are used to prevent overfitting that can happen because very complex networks have many many parameters which tends to overfit the training data.\n",
    "\n",
    "First, let's initialize a model that has too many parameters for the task (many layers and/or many neurons) such that it overfits the training data  \n",
    "**To better see the effect, we will not use any early stopping criterion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T15:25:00.789411Z",
     "start_time": "2021-04-19T15:24:45.792165Z"
    },
    "executionInfo": {
     "elapsed": 81596,
     "status": "ok",
     "timestamp": 1612905145614,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "XaOTe0-Yksyn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation='relu', input_dim=10))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Model compilation\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,  validation_split=0.3,\n",
    "                    epochs=300, batch_size=batch_size, verbose=0)\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'The accuracy on the test set is of {results[1]:.2f}')\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03ZOjwm2ksyo"
   },
   "source": [
    "☝️ In our overparametrized network, some neurons got too specific to given training data, preventing the network from generalizing to new data. This lead to some overfitting. \n",
    "\n",
    "For that reason, we will use \n",
    "- [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layers, whose role is to _cancel_ the output of some neurons  during the training part. By doing this at random, it prevents the network from getting too specific to the input data : no any neuron can be too specific to a given input as its output is sometimes cancelled by the dropout layer. Overall, it forces the information that is contain in one input sample to go through multiple neurons instead of only one specific.\n",
    "\n",
    "- [`Regularizers`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers), as in linear regression regularization where the weights of the linear regression are constrained by L1, L2 or L1 and L2 norms.\n",
    "\n",
    "❓ **Question** ❓ Try adding dropout layers and regularization to all your layers of the above neural network and look at the effect on the loss on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 **Congratulation** \n",
    "\n",
    "Don't forget to commit and push your challenge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "251px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
